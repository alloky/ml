{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from io import open\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "CUDA_DEVICE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = s.lower().strip()\n",
    "    s = re.sub(r\"([,.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('./%s-%s.txt' % (lang1, lang2)).\\\n",
    "        read().strip().split('\\n')\n",
    "\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MAX_LENGTH = 8\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 300108 sentence pairs\n",
      "Trimmed to 184175 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "rus 35877\n",
      "eng 12383\n",
      "['спите ?', 'are you sleeping ?']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'rus', True)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda(CUDA_DEVICE)\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        embedded = self.dropout(embedded)\n",
    "\n",
    "        attn_weights = F.softmax(\n",
    "            self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1)\n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),\n",
    "                                 encoder_outputs.unsqueeze(0))\n",
    "        \n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "        \n",
    "        return output, hidden, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        result = Variable(torch.zeros(1, 1, self.hidden_size))\n",
    "        if use_cuda:\n",
    "            return result.cuda(CUDA_DEVICE)\n",
    "        else:\n",
    "            return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def variableFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    result = Variable(torch.LongTensor(indexes).view(-1, 1))\n",
    "    if use_cuda:\n",
    "        return result.cuda(CUDA_DEVICE)\n",
    "    else:\n",
    "        return result\n",
    "\n",
    "\n",
    "def variablesFromPair(pair):\n",
    "    input_variable = variableFromSentence(input_lang, pair[0])\n",
    "    target_variable = variableFromSentence(output_lang, pair[1])\n",
    "    return (input_variable, target_variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_variable.size()[0]\n",
    "    target_length = target_variable.size()[0]\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda(CUDA_DEVICE) if use_cuda else encoder_outputs\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_variable[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))\n",
    "    decoder_input = decoder_input.cuda(CUDA_DEVICE) if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            decoder_input = target_variable[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            ni = topi[0][0]\n",
    "\n",
    "            decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "            decoder_input = decoder_input.cuda(CUDA_DEVICE) if use_cuda else decoder_input\n",
    "\n",
    "            loss += criterion(decoder_output, target_variable[di])\n",
    "            if ni == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "    \n",
    "    # Если решите использовать  Adam, то лучше клипать градиенты\n",
    "    #torch.nn.utils.clip_grad_norm(encoder.parameters(), 1)\n",
    "    #torch.nn.utils.clip_grad_norm(encoder.parameters(), 1)\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.data[0] / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.001):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate, momentum=0.9, nesterov=True)\n",
    "    # Можно попробовать заюзать Adam\n",
    "    #encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    #decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    \n",
    "    training_pairs = [variablesFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_variable = training_pair[0]\n",
    "        target_variable = training_pair[1]\n",
    "\n",
    "        loss = train(input_variable, target_variable, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    input_variable = variableFromSentence(input_lang, sentence)\n",
    "    input_length = input_variable.size()[0]\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_outputs = Variable(torch.zeros(max_length, encoder.hidden_size))\n",
    "    encoder_outputs = encoder_outputs.cuda(CUDA_DEVICE) if use_cuda else encoder_outputs\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_variable[ei],\n",
    "                                                 encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_outputs[ei] + encoder_output[0][0]\n",
    "\n",
    "    decoder_input = Variable(torch.LongTensor([[SOS_token]]))  # SOS\n",
    "    decoder_input = decoder_input.cuda(CUDA_DEVICE) if use_cuda else decoder_input\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    decoded_words = []\n",
    "    decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "    for di in range(max_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "            decoder_input, decoder_hidden, encoder_outputs)\n",
    "        decoder_attentions[di] = decoder_attention.data\n",
    "        topv, topi = decoder_output.data.topk(1)\n",
    "        ni = topi[0][0]\n",
    "        if ni == EOS_token:\n",
    "            decoded_words.append('<EOS>')\n",
    "            break\n",
    "        else:\n",
    "            decoded_words.append(output_lang.index2word[ni])\n",
    "\n",
    "        decoder_input = Variable(torch.LongTensor([[ni]]))\n",
    "        decoder_input = decoder_input.cuda(CUDA_DEVICE) if use_cuda else decoder_input\n",
    "\n",
    "    return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0m 12s (- 159m 46s) (100 0%) 5.5487\n",
      "0m 17s (- 106m 36s) (200 0%) 5.2587\n",
      "0m 20s (- 83m 58s) (300 0%) 5.2448\n",
      "0m 23s (- 73m 51s) (400 0%) 5.2944\n",
      "0m 27s (- 68m 51s) (500 0%) 4.9910\n",
      "0m 32s (- 67m 46s) (600 0%) 4.6916\n",
      "0m 38s (- 67m 34s) (700 0%) 4.8292\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-1df501195ade>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mattn_decoder1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCUDA_DEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_decoder1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m75000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-16-37c3607e7502>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         loss = train(input_variable, target_variable, encoder,\n\u001b[0;32m---> 23\u001b[0;31m                      decoder, encoder_optimizer, decoder_optimizer, criterion)\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-64e1b6ad3f23>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_variable, target_variable, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mei\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         encoder_output, encoder_hidden = encoder(\n\u001b[0;32m---> 20\u001b[0;31m             input_variable[ei], encoder_hidden)\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mei\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_output\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-11-00bfce7e76b0>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hidden)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0membedded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgru\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0mflat_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflat_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         )\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_packed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPackedSequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(input, *fargs, **fkwargs)\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhack_onnx_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36m_do_forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    326\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m         \u001b[0mflat_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_iter_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mflat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNestedIOFunction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mflat_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0mnested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0mnested_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_unflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/function.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mnested_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_map_variable_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_extended\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnested_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nested_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py\u001b[0m in \u001b[0;36mforward_extended\u001b[0;34m(self, input, weight, hx)\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0mhy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 294\u001b[0;31m         \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(fn, input, hx, weight, output, hy)\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0m_copyParams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_weight_descriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_buf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m             \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_buf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/backends/cudnn/rnn.py\u001b[0m in \u001b[0;36minit_weight_descriptor\u001b[0;34m(fn, weight)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mw_desc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFilterDescriptor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0mw_view\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# seems that filters require >=3 dimensions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     \u001b[0mw_desc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mw_desc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/backends/cudnn/__init__.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, weight)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mdatatype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_typemap\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m         check_error(lib.cudnnSetFilterNdDescriptor(\n\u001b[1;32m    190\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatatype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCUDNN_TENSOR_NCHW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mtype\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    394\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_CudaBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0m__new__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lazy_new\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1)\n",
    "\n",
    "\n",
    "if use_cuda:\n",
    "    encoder1 = encoder1.cuda(CUDA_DEVICE)\n",
    "    attn_decoder1 = attn_decoder1.cuda(CUDA_DEVICE)\n",
    "\n",
    "trainIters(encoder1, attn_decoder1, 75000, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> мой план лучше , чем ваш .\n",
      "= my plan is better than yours .\n",
      "< i you you . . <EOS>\n",
      "\n",
      "> том находится на аппарате жизнеобеспечения .\n",
      "= tom is on life support .\n",
      "< i you you . . <EOS>\n",
      "\n",
      "> на ней было красивое платье .\n",
      "= she was wearing a beautiful dress .\n",
      "< i you you . . <EOS>\n",
      "\n",
      "> я играла в теннис .\n",
      "= i used to play tennis .\n",
      "< i you you . . <EOS>\n",
      "\n",
      "> пойдём пешком .\n",
      "= let's walk .\n",
      "< i is . . <EOS>\n",
      "\n",
      "> было шумно .\n",
      "= it was noisy .\n",
      "< i is . . <EOS>\n",
      "\n",
      "> прошу прощения , я опоздала .\n",
      "= i'm sorry i was late .\n",
      "< i you you . . <EOS>\n",
      "\n",
      "> ты хочешь это обсудить ?\n",
      "= do you want to discuss it ?\n",
      "< you you you you ? <EOS>\n",
      "\n",
      "> я даже комментировать ничего не собираюсь .\n",
      "= i'm not even going to comment .\n",
      "< i you you . . <EOS>\n",
      "\n",
      "> впервые слышу .\n",
      "= it's news to me .\n",
      "< i is . . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = меня зовут том .\n",
      "output = i is . . . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3fefce1160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"меня зовут том .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = я приехал вчера вечером .\n",
      "output = i you you . . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3fe9fb2c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"я приехал вчера вечером .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = куда положить деньги .\n",
      "output = i you . . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3fc4ac5588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"куда положить деньги .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
